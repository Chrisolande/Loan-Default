---
title: "Feature Selection Techniques for Loan Default Prediction"
author: "Data Scientist"
date: "March 2, 2025"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  fig.width = 10,
  fig.height = 6
)
```

# Feature Selection Techniques for Loan Default Prediction

This document demonstrates various feature selection techniques using a loan default dataset from Kaggle. We'll explore different methods for identifying the most relevant features for predicting loan defaults.

## 1. Loading Required Packages

```{r load-packages}
# Install packages if not already installed
# install.packages(c("tidyverse", "tidymodels", "vip", "corrplot", "skimr", "GGally", 
#                   "caret", "randomForest", "xgboost", "pROC", "glmnet", "doParallel"))

# Load packages
library(tidyverse)     # For data manipulation and visualization
library(tidymodels)    # For modeling framework
library(vip)           # For variable importance
library(corrplot)      # For correlation matrix visualization
library(skimr)         # For data summary
library(GGally)        # For ggpairs plots
library(caret)         # For RFE
library(randomForest)  # For random forest
library(xgboost)       # For XGBoost
library(pROC)          # For ROC curves
library(glmnet)        # For LASSO and Elastic Net
library(doParallel)    # For parallel processing

```
## 2. Loading and Exploring the Data

Let's load the loan default dataset from Kaggle and explore its structure.

```{r load-data}
# Set the file path - adjust the path to where you downloaded the dataset
# For this example, we'll load a sample of the data (for demonstration purposes)
# In a real scenario, you would use:
# loan_data <- read.csv("path/to/your/loan_default_data.csv")

# For demonstration, we'll simulate a loan default dataset based on common features
```
```{r}
set.seed(123)
n <- 5000

# Generate a synthetic loan default dataset
loan_data <- tibble(
  loan_id = 1:n,
  loan_amount = rnorm(n, mean = 10000, sd = 5000),
  interest_rate = runif(n, min = 5, max = 15),
  term = sample(c(36, 60, 84), n, replace = TRUE),
  credit_score = rnorm(n, mean = 680, sd = 80),
  annual_income = rlnorm(n, meanlog = 11, sdlog = 0.5),
  employment_length = rpois(n, lambda = 5),
  home_ownership = sample(c("RENT", "OWN", "MORTGAGE"), n, replace = TRUE, prob = c(0.4, 0.2, 0.4)),
  debt_to_income = rnorm(n, mean = 18, sd = 8),
  loan_purpose = sample(c("DEBT_CONSOLIDATION", "HOME_IMPROVEMENT", "MAJOR_PURCHASE", "EDUCATION", "OTHER"), 
                        n, replace = TRUE),
  open_accounts = rpois(n, lambda = 10),
  delinquent_accounts = rpois(n, lambda = 0.5),
  inquiries_last_6mo = rpois(n, lambda = 1),
  bankruptcies = rbinom(n, size = 1, prob = 0.05),
  months_since_last_delinquency = sample(c(NA, 1:120), n, replace = TRUE, prob = c(0.7, rep(0.3/120, 120))),
  total_credit_lines = rpois(n, lambda = 20)
)

# Create the target variable (default)
# We'll use a logistic model to create realistic relationships
log_odds <- -5 + 
  0.0001 * loan_data$loan_amount + 
  0.2 * (loan_data$interest_rate - 10) + 
  -0.005 * (loan_data$credit_score - 680) + 
  -0.2 * log(loan_data$annual_income / 50000) + 
  0.1 * (loan_data$debt_to_income - 15) + 
  0.5 * loan_data$delinquent_accounts + 
  0.3 * loan_data$inquiries_last_6mo +
  1.5 * loan_data$bankruptcies

prob_default <- 1 / (1 + exp(-log_odds))
loan_data$loan_status <- rbinom(n, size = 1, prob = prob_default)
loan_data$loan_status <- factor(loan_data$loan_status, levels = c(0, 1), labels = c("Current", "Default"))

# Convert categorical variables to factors
loan_data$home_ownership <- as.factor(loan_data$home_ownership)
loan_data$loan_purpose <- as.factor(loan_data$loan_purpose)

# Display the first few rows of the dataset
head(loan_data)
```

## 3. Data Summary and Preprocessing

Let's examine the dataset summary and preprocess the data.

```{r data-summary}
# Summary of the dataset
skim(loan_data)

# Check class imbalance
loan_data %>%
  count(loan_status) %>%
  mutate(pct = n / sum(n))

# Check missing values
colSums(is.na(loan_data))

# Handle missing values
loan_data <- loan_data %>%
  mutate(months_since_last_delinquency = replace_na(months_since_last_delinquency, 999))  # 999 indicates never had a delinquency

# Split data into training and testing sets
set.seed(42)
loan_split <- initial_split(loan_data, prop = 0.8, strata = loan_status)
loan_train <- training(loan_split)
loan_test <- testing(loan_split)

# Create a recipe for preprocessing
loan_recipe <- recipe(loan_status ~ ., data = loan_train) %>%
  step_rm(loan_id) %>%  # Remove ID column
  step_dummy(all_nominal_predictors()) %>%  # Create dummy variables for categorical predictors
  step_normalize(all_numeric_predictors()) %>%  # Normalize numeric predictors
  step_zv(all_predictors())  # Remove zero-variance predictors

# Prepare the recipe
loan_prep <- prep(loan_recipe)
loan_train_processed <- bake(loan_prep, new_data = loan_train)
loan_test_processed <- bake(loan_prep, new_data = loan_test)

# Check the processed data
glimpse(loan_train_processed)
```

## 4. Correlation Analysis

One of the simplest methods for feature selection is correlation analysis.

```{r correlation-analysis}
# Select numeric variables for correlation analysis (excluding the target)
numeric_vars <- loan_train %>%
  select(where(is.numeric), -loan_id) %>%
  names()

# Create correlation matrix
cor_matrix <- cor(loan_train[numeric_vars])

# Visualize correlation matrix
corrplot(cor_matrix, method = "circle", type = "upper", 
         tl.col = "black", tl.srt = 45, addCoef.col = "black",
         number.cex = 0.7, tl.cex = 0.7,
         title = "Correlation Matrix of Numeric Variables")

# Find highly correlated features (threshold = 0.7)
high_cor <- findCorrelation(cor_matrix, cutoff = 0.7)
if(length(high_cor) > 0) {
  cat("Highly correlated features that could be removed:", 
      paste(numeric_vars[high_cor], collapse = ", "))
} else {
  cat("No highly correlated features found at the 0.7 threshold.")
}

# Calculate point-biserial correlation with the target variable
target_cors <- sapply(loan_train[numeric_vars], function(x) {
  cor(as.numeric(loan_train$loan_status) - 1, x)
})

# Visualize correlations with the target
data.frame(Variable = names(target_cors), Correlation = target_cors) %>%
  mutate(abs_cor = abs(Correlation)) %>%
  arrange(desc(abs_cor)) %>%
  mutate(Variable = factor(Variable, levels = Variable)) %>%
  ggplot(aes(x = reorder(Variable, abs_cor), y = Correlation, fill = Correlation)) +
  geom_bar(stat = "identity") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  coord_flip() +
  labs(title = "Correlation with Loan Default",
       x = "Features", y = "Correlation Coefficient") +
  theme_minimal()

```
## 5. Feature Importance from Tree-Based Models

Tree-based models like Random Forest and XGBoost can provide feature importance scores.

### 5.1 Random Forest Feature Importance

```{r rf-importance}
# Train a Random Forest model
set.seed(123)
rf_model <- rand_forest() %>%
  set_engine("randomForest") %>%
  set_mode("classification") %>%
  fit(loan_status ~ ., data = loan_train_processed)

# Variable importance plot
vip(rf_model, num_features = 15) +
  labs(title = "Random Forest Variable Importance")

# Get detailed importance scores
rf_importance <- rf_model$fit$importance
rf_importance_df <- data.frame(
  Feature = rownames(rf_importance),
  Importance = rf_importance[, "MeanDecreaseGini"]
) %>%
  arrange(desc(Importance))

rf_importance_df %>%
  head(15) %>%
  ggplot(aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Top 15 Features by Random Forest Importance",
       x = "Features",
       y = "Importance (Mean Decrease in Gini Index)") +
  theme_minimal()

```
### 5.2 XGBoost Feature Importance

```{r xgb-importance}
# Train an XGBoost model
set.seed(123)
xgb_model <- boost_tree() %>%
  set_engine("xgboost") %>%
  set_mode("classification") %>%
  fit(loan_status ~ ., data = loan_train_processed)

# Variable importance plot for XGBoost
vip(xgb_model, num_features = 15) +
  labs(title = "XGBoost Variable Importance")

# Get XGBoost importance scores
xgb_importance <- xgb.importance(
  model = xgb_model$fit,
  feature_names = colnames(loan_train_processed %>% select(-loan_status))
)

# Plot XGBoost importance
xgb.plot.importance(xgb_importance, top_n = 15, measure = "Gain", 
                   main = "XGBoost Feature Importance (Gain)")

```
## 6. Recursive Feature Elimination (RFE)

RFE is a feature selection method that recursively removes the weakest feature(s) until the specified number of features is reached.

```{r rfe, results='hide'}
# Set up parallel processing for faster computation
registerDoParallel(cores = 4)

# Define control parameters for RFE
rfe_control <- rfeControl(
  functions = rfFuncs,  # Use random forest
  method = "cv",        # Cross-validation
  number = 5,           # 5-fold CV
  verbose = FALSE,
  allowParallel = TRUE
)

# Run RFE
set.seed(123)
rfe_result <- rfe(
  x = loan_train_processed %>% select(-loan_status),
  y = loan_train_processed$loan_status,
  sizes = c(1:10, 15, 20),  # Evaluate these subset sizes
  rfeControl = rfe_control
)

# Stop parallel processing
stopImplicitCluster()

```
```{r rfe-results}
# Print RFE results
print(rfe_result)

# Plot the results
plot(rfe_result, type = c("g", "o"))

# Get the optimal features
optimal_vars <- predictors(rfe_result)
cat("Optimal features selected by RFE:", paste(optimal_vars, collapse = ", "))

# Plot the selected feature set performance
ggplot(data = data.frame(
  Variables = rfe_result$results$Variables,
  Accuracy = rfe_result$results$Accuracy
)) +
  geom_line(aes(x = Variables, y = Accuracy), color = "blue") +
  geom_point(aes(x = Variables, y = Accuracy), color = "red", size = 3) +
  geom_vline(xintercept = rfe_result$optsize, linetype = "dashed", color = "darkred") +
  annotate("text", x = rfe_result$optsize + 2, y = min(rfe_result$results$Accuracy), 
           label = paste("Optimal size:", rfe_result$optsize), hjust = 0) +
  labs(title = "RFE Feature Selection Results",
       x = "Number of Features",
       y = "Accuracy") +
  theme_minimal()
```

## 7. LASSO Regression for Feature Selection

LASSO (Least Absolute Shrinkage and Selection Operator) can be used for feature selection by shrinking some coefficients to exactly zero.

```{r lasso-selection}
# Set up LASSO
set.seed(123)
lasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

# Set up the workflow
lasso_wf <- workflow() %>%
  add_model(lasso_spec) %>%
  add_recipe(
    recipe(loan_status ~ ., data = loan_train) %>%
      step_rm(loan_id) %>%
      step_dummy(all_nominal_predictors()) %>%
      step_normalize(all_numeric_predictors()) %>%
      step_zv(all_predictors())
  )


# Set up grid of lambda values
lambda_grid <- grid_regular(penalty(), levels = 50)

# Set up resampling
folds <- vfold_cv(loan_train, v = 5, strata = loan_status)

# Tune LASSO model
lasso_tune <- lasso_wf %>%
  tune_grid(resamples = folds,
            grid = lambda_grid,
            metrics = metric_set(roc_auc))

# Get best lambda
best_lambda <- lasso_tune %>%
  select_best("roc_auc")

# Finalize workflow and fit model
lasso_final <- lasso_wf %>%
  finalize_workflow(best_lambda) %>%
  fit(data = loan_train)

# Extract lasso coefficients
lasso_coefs <- lasso_final %>%
  extract_fit_parsnip() %>%
  tidy() %>%
  filter(estimate != 0, term != "(Intercept)") %>%
  arrange(desc(abs(estimate)))

# Visualize LASSO coefficients
lasso_coefs %>%
  mutate(term = str_replace_all(term, "home_ownership_", "Home: ")) %>%
  mutate(term = str_replace_all(term, "loan_purpose_", "Purpose: ")) %>%
  slice_head(n = 20) %>%
  ggplot(aes(x = reorder(term, abs(estimate)), y = estimate, fill = estimate > 0)) +
  geom_col() +
  scale_fill_manual(values = c("red", "blue"), labels = c("Negative", "Positive")) +
  coord_flip() +
  labs(title = "Top 20 LASSO Coefficients",
       x = "Features",
       y = "Coefficient Estimate",
       fill = "Direction") +
  theme_minimal()

# Plot the tuning results
autoplot(lasso_tune) +
  labs(title = "LASSO Tuning Results")

# Get non-zero coefficients across different lambda values
lasso_model <- extract_fit_parsnip(lasso_final)$fit
lasso_cv <- cv.glmnet(x = as.matrix(loan_train_processed %>% select(-loan_status, -loan_id)),
                      y = loan_train_processed$loan_status,
                      alpha = 1,
                      family = "binomial")

# Plot the coefficient path
plot(lasso_model, "lambda", label = TRUE)

```
## 8. Elastic Net for Feature Selection

Elastic Net combines L1 (LASSO) and L2 (Ridge) penalties and can be useful when dealing with correlated predictors.

```{r elastic-net}
# Set up Elastic Net
set.seed(123)
enet_spec <- logistic_reg(penalty = tune(), mixture = tune()) %>%
  set_engine("glmnet")

# Set up the workflow
enet_wf <- workflow() %>%
  add_model(enet_spec) %>%
  add_recipe(
    recipe(loan_status ~ ., data = loan_train) %>%
      step_rm(loan_id) %>%
      step_dummy(all_nominal_predictors()) %>%
      step_normalize(all_numeric_predictors()) %>%
      step_zv(all_predictors())
  )


enet_tune <- enet_wf %>%
  tune_bayes(
    resamples = folds,
    param_info = parameters(penalty(range = c(1e-4, 1)), mixture(range = c(0, 1))),  
    metrics = metric_set(roc_auc),
    iter = 20,  # Number of search iterations
    initial = 5,  # Start with 5 random trials before Bayesian search
    control = control_bayes(no_improve = 5, verbose = TRUE)  # Stops if no improvement after 5 iterations
  )
# Visualize tuning results
autoplot(enet_tune) +
  labs(title = "Elastic Net Tuning Results")

# Get best hyperparameters
best_enet <- enet_tune %>%
  select_best("roc_auc")

# Finalize workflow and fit model
enet_final <- enet_wf %>%
  finalize_workflow(best_enet) %>%
  fit(data = loan_train)

# Extract Elastic Net coefficients
enet_coefs <- enet_final %>%
  extract_fit_parsnip() %>%
  tidy() %>%
  filter(estimate != 0, term != "(Intercept)") %>%
  arrange(desc(abs(estimate)))

# Visualize Elastic Net coefficients
enet_coefs %>%
  mutate(term = str_replace_all(term, "home_ownership_", "Home: ")) %>%
  mutate(term = str_replace_all(term, "loan_purpose_", "Purpose: ")) %>%
  slice_head(n = 20) %>%
  ggplot(aes(x = reorder(term, abs(estimate)), y = estimate, fill = estimate > 0)) +
  geom_col() +
  scale_fill_manual(values = c("red", "blue"), labels = c("Negative", "Positive")) +
  coord_flip() +
  labs(title = "Top 20 Elastic Net Coefficients",
       x = "Features",
       y = "Coefficient Estimate",
       fill = "Direction") +
  theme_minimal()
```

## 9. Comparing Feature Selection Methods

Let's compare the top features selected by different methods.

```{r compare-methods}
# Get top 10 features from each method
top_corr <- data.frame(Variable = names(target_cors), Correlation = abs(target_cors)) %>%
  arrange(desc(Correlation)) %>%
  slice_head(n = 10) %>%
  pull(Variable)

top_rf <- rf_importance_df %>%
  slice_head(n = 10) %>%
  pull(Feature)

top_xgb <- xgb_importance %>%
  slice_head(n = 10) %>%
  pull(Feature)

top_rfe <- optimal_vars[1:min(10, length(optimal_vars))]

top_lasso <- lasso_coefs %>%
  slice_head(n = 10) %>%
  pull(term)

top_enet <- enet_coefs %>%
  slice_head(n = 10) %>%
  pull(term)

# Function to clean feature names
clean_names <- function(names) {
  names <- gsub("home_ownership_", "home_", names)
  names <- gsub("loan_purpose_", "purpose_", names)
  return(names)
}

# Clean feature names
top_corr_clean <- clean_names(top_corr)
top_rf_clean <- clean_names(top_rf)
top_xgb_clean <- clean_names(top_xgb)
top_rfe_clean <- clean_names(top_rfe)
top_lasso_clean <- clean_names(top_lasso)
top_enet_clean <- clean_names(top_enet)

# Create a comparison dataframe
comparison_df <- data.frame(
  Correlation = c(top_corr_clean, rep(NA, 10 - length(top_corr_clean))),
  RandomForest = c(top_rf_clean, rep(NA, 10 - length(top_rf_clean))),
  XGBoost = c(top_xgb_clean, rep(NA, 10 - length(top_xgb_clean))),
  RFE = c(top_rfe_clean, rep(NA, 10 - length(top_rfe_clean))),
  LASSO = c(top_lasso_clean, rep(NA, 10 - length(top_lasso_clean))),
  ElasticNet = c(top_enet_clean, rep(NA, 10 - length(top_enet_clean)))
)

# Display the comparison
knitr::kable(comparison_df, caption = "Top 10 Features from Each Method")

# Create a function to get feature importance score or count across methods
count_feature_importance <- function(feature, methods_list) {
  sum(sapply(methods_list, function(method) feature %in% method))
}

# Combine all methods' top features
all_features <- unique(c(top_corr_clean, top_rf_clean, top_xgb_clean, 
                         top_rfe_clean, top_lasso_clean, top_enet_clean))
all_features <- all_features[!is.na(all_features)]

# Count feature presence across methods
feature_counts <- sapply(all_features, function(feat) {
  count_feature_importance(feat, list(top_corr_clean, top_rf_clean, top_xgb_clean, 
                                     top_rfe_clean, top_lasso_clean, top_enet_clean))
})

# Create a dataframe for visualization
feature_counts_df <- data.frame(
  Feature = names(feature_counts),
  Count = as.numeric(feature_counts)
)

# Plot feature counts
feature_counts_df %>%
  arrange(desc(Count)) %>%
  slice_head(n = 20) %>%
  ggplot(aes(x = reorder(Feature, Count), y = Count, fill = Count)) +
  geom_bar(stat = "identity") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  coord_flip() +
  labs(title = "Feature Importance Consensus",
       subtitle = "Number of methods that selected the feature in their top 10",
       x = "Feature",
       y = "Count of Methods") +
  theme_minimal()

```
## 10. Model Performance with Selected Features

Let's evaluate how different feature sets perform in predicting loan defaults.

```{r model-performance}
# Define a function to train and evaluate a model
evaluate_feature_set <- function(features, name) {
  # Create a recipe with just the selected features
  feature_recipe <- recipe(loan_status ~ ., data = loan_train %>% select(loan_status, loan_id, all_of(features))) %>%
    step_rm(loan_id) %>%
    step_dummy(all_nominal_predictors()) %>%
    step_normalize(all_numeric_predictors()) %>%
    step_zv(all_predictors())
  
  # Prep the recipe
  feature_prep <- prep(feature_recipe)
  train_processed <- bake(feature_prep, new_data = loan_train)
  test_processed <- bake(feature_prep, new_data = loan_test)
  
  # Train a random forest model
  rf_model <- rand_forest() %>%
    set_engine("randomForest") %>%
    set_mode("classification") %>%
    fit(loan_status ~ ., data = train_processed)
  
  # Make predictions
  preds <- predict(rf_model, test_processed, type = "prob") %>%
    bind_cols(test_processed) %>%
    select(loan_status, .pred_Default)
  
  # Calculate performance metrics
  roc_obj <- roc(preds$loan_status, preds$.pred_Default)
  auc_value <- auc(roc_obj)
  
  # Return results
  return(list(
    name = name,
    auc = auc_value,
    roc = roc_obj,
    features = features
  ))
}

# Get the most important features from each method
# For methods that returned terms with prefixes (like LASSO and Elastic Net), extract the base variable names
get_base_features <- function(terms) {
  base_features <- unique(sapply(terms, function(term) {
    if(grepl("home_ownership_", term)) {
      return("home_ownership")
    } else if(grepl("loan_purpose_", term)) {
      return("loan_purpose")
    } else {
      return(term)
    }
  }))
  return(base_features)
}

# Get top features from each method, focusing on the base variable name
corr_features <- top_corr
rf_features <- get_base_features(top_rf)
xgb_features <- get_base_features(top_xgb)
rfe_features <- get_base_features(top_rfe)
lasso_features <- get_base_features(top_lasso)
enet_features <- get_base_features(top_enet)

# Get consensus features (features that appear in multiple methods)
all_base_features <- unique(c(corr_features, rf_features, xgb_features, rfe_features, 
                            get_base_features(top_lasso), get_base_features(top_enet)))
all_base_features <- all_base_features[!is.na(all_base_features)]

feature_counts <- sapply(all_base_features, function(feat) {
  sum(feat %in% corr_features, 
      feat %in% rf_features,
      feat %in% xgb_features,
      feat %in% rfe_features,
      feat %in% get_base_features(top_lasso),
      feat %in% get_base_features(top_enet))
})

consensus_features <- names(feature_counts[feature_counts >= 3])

# Evaluate each feature set
set.seed(123)
results_list <- list(
  evaluate_feature_set(corr_features, "Correlation"),
  evaluate_feature_set(rf_features, "Random Forest"),
  evaluate_feature_set(xgb_features, "XGBoost"),
  evaluate_feature_set(rfe_features, "RFE"),
  evaluate_feature_set(get_base_features(top_lasso), "LASSO"),
  evaluate_feature_set(get_base_features(top_enet), "Elastic Net"),
  evaluate_feature_set(consensus_features, "Consensus (3+ methods)")
)

# Plot ROC curves
colors <- c("red", "blue", "green", "purple", "orange", "brown", "black")
plot(results_list[[1]]$roc, col = colors[1], main = "ROC Curves for Different Feature Sets")
for(i in 2:length(results_list)) {
  lines(results_list[[i]]$roc, col = colors[i])
}
legend("bottomright", 
       legend = sapply(results_list, function(r) paste0(r$name, " (AUC = ", round(r$auc, 3), ")")),
       col = colors,
       lwd = 2)

# Compare AUC values
auc_df <- data.frame(
  Method = sapply(results_list, function(r) r$name),
  AUC = sapply(results_list, function(r) r$auc),
  Features = sapply(results_list, function(r) length(r$features))
)

# Plot AUC comparison
auc_df %>%
  ggplot(aes(x = reorder(Method, AUC), y = AUC, fill = Features)) +
  geom_bar(stat = "identity") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  coord_flip() +
  labs(title = "Model Performance with Different Feature Sets",
       x = "Feature Selection Method",
       y = "AUC Score",
       fill = "Number of Features") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

## 11. Final Feature Selection Recommendation

Based on our comprehensive analysis, we can make an informed recommendation about which features to use for building a loan default prediction model.

```{r final-recommendation}
# Get the best performing feature set
best_method <- auc_df %>%
  arrange(desc(AUC)) %>%
  slice_head(n = 1)

best_method_name <- best_method$Method
best_method_idx <- which(sapply(results_list, function(r) r$name) == best_method_name)
best_features <- results_list[[best_method_idx]]$features

# Print the recommendation
cat("## Feature Selection Recommendation\n\n")
cat("Based on our analysis, the *", best_method_name, "* approach provides the best performance with an AUC of ", 
    round(best_method$AUC, 3), " using ", best_method$Features, " features.\n\n", sep = "")
cat("The recommended features for the loan default prediction model are:\n\n")
cat(paste("- ", best_features, collapse = "\n"))

# Create a final model with the recommended features
final_recipe <- recipe(loan_status ~ ., data = loan_train %>% 
                       select(loan_status, loan_id, all_of(best_features))) %>%
  step_rm(loan_id) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_zv(all_predictors())
```