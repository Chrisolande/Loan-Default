{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.4.0"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3106815,"sourceType":"datasetVersion","datasetId":1897041}],"dockerImageVersionId":30749,"isInternetEnabled":true,"language":"r","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Introduction\n\nThis document presents an intensive exploratory loan_data analysis (EDA) and statistical analysis of a loan status loan_dataset. The goal is to uncover patterns, relationships, and insights that can help predict loan statuss. The analysis includes:\n\n- loan_data preprocessing and cleaning\n- Univariate analysis with advanced visualizations\n- Bivariate and multivariate analysis\n- Correlation analysis with sophisticated visualizations\n- Feature importance and selection\n- Statistical modeling and predictive analysis\n- Advanced dimensionality reduction and visualization techniques\n\nLet's begin by loading and examining the loan_dataset.\n\n# 2. loan_data Loading and Initial Exploration","metadata":{}},{"cell_type":"code","source":"remotes::install_github(\"arleyc/PCAtest\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T21:51:36.933120Z","iopub.execute_input":"2025-03-03T21:51:36.935015Z","iopub.status.idle":"2025-03-03T21:51:52.763282Z","shell.execute_reply":"2025-03-03T21:51:52.760617Z"}},"outputs":[{"name":"stderr","text":"Downloading GitHub repo arleyc/PCAtest@HEAD\n\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m──\u001b[39m \u001b[36mR CMD build\u001b[39m \u001b[36m─────────────────────────────────────────────────────────────────\u001b[39m\n* checking for file ‘/tmp/RtmpQnBw1S/remotes21737d2cac/arleyc-PCAtest-7e10abe/DESCRIPTION’ ... OK\n* preparing ‘PCAtest’:\n* checking DESCRIPTION meta-information ... OK\n* checking for LF line-endings in source and make files and shell scripts\n* checking for empty or unneeded directories\n  NB: this package now depends on R (>= 3.5.0)\n  WARNING: Added dependency on R >= 3.5.0 because serialized objects in\n  serialize/load version 3 cannot be read in older versions of R.\n  File(s) containing such objects:\n    ‘PCAtest/data/ants.rda’ ‘PCAtest/data/ex0.rda’\n    ‘PCAtest/data/ex025.rda’ ‘PCAtest/data/ex05.rda’\n* building ‘PCAtest_0.0.2.tar.gz’\n\n","output_type":"stream"},{"name":"stderr","text":"Installing package into ‘/usr/local/lib/R/site-library’\n(as ‘lib’ is unspecified)\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"librarian::shelf(tidyverse, tidymodels, DataExplorer, GGally, corrplot, plotly, viridis,\npROC, factoextra, cluster, ggthemes, ggridges, scales, vcd, kableExtra, DT, \nMASS, Rtsne, tsne, umap, conflicted, caTools, gridExtra,scales, entropy, RColorBrewer,\nigraph, ggraph, qgraph, PCAtest)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set custom theme\n\ntheme_custom <- function() {\n  theme_minimal() +\n    theme(\n      plot.background = element_rect(fill = \"white\", color = NA),\n      panel.grid.major = element_line(color = \"gray90\"),\n      panel.grid.minor = element_blank(),\n      plot.title = element_text(size = 16, face = \"bold\", hjust = 0.5),\n      plot.subtitle = element_text(size = 12, color = \"gray30\", hjust = 0.5),\n      axis.title = element_text(size = 12, face = \"bold\"),\n      axis.text = element_text(size = 10),\n      legend.title = element_text(size = 12, face = \"bold\"),\n      legend.text = element_text(size = 10),\n      legend.position = \"right\"\n    )\n}\n\ntheme_set(theme_custom())\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conflicted::conflicts_prefer(dplyr::select)\ntidymodels_prefer()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loan_data <- read_csv(\"dataset/Loan_Default.csv\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loan_data %>% \n  janitor::clean_names() %>%\n  select(-id) -> loan_data\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select 20000 observations while maintaining the distribution in the target variable\n# for fast modelling and visualization before upscaling\n#set.seed(42)\n\n#split_ratio <- 1000 / nrow(loan_data)\n#split_index <- sample.split(loan_data$status, SplitRatio = split_ratio)\n\n# Extract the sample\n#data <- loan_data[split_index, ]\n\ndata<- loan_data","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify if the distribution is maintained\nprint(table(loan_data$status) / nrow(loan_data))\nprint(table(data$status) / nrow(data))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat(\"Dimensions of the loan_dataset\", dim(data)[1], \"rows and \", dim(data)[2], \" columns\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"head(data)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"skimr::skim(data) %>% \n  as_tibble() %>% \n  kable(caption = \"Summary Statistics of the loan loan_data\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert all character loan_amounts to factors\n\ndata <- data %>% mutate_if(is.character, as.factor)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Missing loan_data Analysis\n","metadata":{}},{"cell_type":"code","source":"plot_missing(data, missing_only = TRUE, title = \"Missing Values Bar Chart\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        plot.title = element_text(face = \"bold\"))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Convert all character variables to factors\ndata <- data %>% \n  mutate_if(is.character, as.factor)\n\nhead(data)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove Zero Variance columns and then perform knn imputation\ndata <- recipe(status ~ ., data) %>% \n  step_zv(all_predictors()) %>% \n  step_impute_knn(all_predictors()) %>% \n  prep() %>% \n  bake(new_data = NULL)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"colSums(is.na(data))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Univariate Analysis\n\n## 3.1 Distribution of Numeric loan_amounts","metadata":{}},{"cell_type":"code","source":"data$status <- factor(data$status, \n  levels = c(0, 1), \n  labels = c(\"No\", \"Yes\"))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"status_counts <- data %>% \n  count(status) %>% \n  mutate(percentage = n / sum(n) * 100)\n\nggplot(data, aes(status, fill = status)) +\n  geom_bar(width = 0.7) +\n  geom_text(stat = \"count\", \n             aes(label = after_stat(count)),\n             vjust = -0.5,\n             size = 4, fontface = \"bold\") +\n  scale_fill_viridis_d(option = \"D\") +\n  labs(title = \"Loan Status Counts\",\n      subtitle = paste(\"Total loans =\", nrow(data)),\n      fill = \"Loan Status\") +\n  theme_custom() -> p1\n\np1","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_cols <- data %>% \n  select_if(is.numeric) %>% \n  names()\n\nnumeric_data <- data %>% \n  select(any_of(c(numeric_cols, \"status\"))) %>% \n  pivot_longer(cols = -status, names_to = \"features\", values_to = \"values\")\n\np2 <- ggplot(numeric_data, aes(values, fill = status)) +\n  geom_density(alpha = 0.6) +\n  geom_rug(alpha = 0.6, color = \"#e74c3c\") +\n  facet_wrap(~features, scales = \"free\") +\n  labs(title = \"Feature Distributions by Loan Status\",\n  x = \"Value\", y = \"Density\") +\n  scale_fill_manual(values = c(\"No\" = \"#66c2a5\", \n  \"Yes\" = \"#fc8d62\")) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1),\n     legend.position = \"bottom\")\n\np2\n  ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to plot boxplots with violin overlay\nplot_box <- function(data, variable) {\n  q <- quantile(data[[variable]], probs = c(0.25, 0.75), na.rm = TRUE)\n  iqr <- diff(q)\n  bounds <- q + c(-1.5, 1.5) * iqr\n  outlier_pct <- mean(data[[variable]] < bounds[1] | data[[variable]] > bounds[2], na.rm = TRUE) * 100\n  \n  ggplot(data, aes(y = .data[[variable]], x = \"\")) +\n    geom_violin(fill = \"#9b59b6\", alpha = 0.6) +\n    geom_boxplot(width = 0.1, fill = \"#3498db\", alpha = 0.7, outlier.color = \"#e74c3c\") +\n    labs(\n      title = paste(\"Distribution of\", variable),\n      subtitle = sprintf(\"IQR = %.2f | Outliers = %.2f%%\", iqr, outlier_pct),\n      y = variable, x = \"\"\n    ) +\n    theme_minimal()\n}\n\n# Generate and arrange plots for first 9 numeric features\nplots <- lapply(head(numeric_cols, 9), plot_box, data = data)\ngrid.arrange(grobs = plots, ncol = 3)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Distribution of categorical features","metadata":{}},{"cell_type":"code","source":"categorical_cols <- data %>% \n  select(where(~ !is.numeric(.))) %>% \n  names()\n\ncategorical_cols","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":" \noptions(repr.plot.height = 24, repr.plot.width = 24)\n\nif (length(categorical_cols) > 0) {\n  \n  \n  plot_bar <- function(data, variable) {\n    freq_table <- table(data[[variable]])\n    freq_df <- as.data.frame(freq_table) %>%\n      rename(Category = Var1, Count = Freq) %>%\n      mutate(Percentage = Count / sum(Count) * 100) %>%\n      arrange(desc(Count))\n    \n    # Compute Shannon's entropy\n    entropy_value <- entropy(freq_df$Count, unit = \"log2\")\n    norm_entropy <- entropy_value / log2(nrow(freq_df))\n    \n    # Plot\n    ggplot(freq_df, aes(reorder(Category, -Count), Count)) +\n      geom_bar(stat = \"identity\", fill = \"#2ecc71\", alpha = 0.8) +\n      geom_text(aes(label = sprintf(\"%.1f%%\", Percentage)), \n                vjust = -0.5, color = \"black\", size = 3) +\n      labs(\n        title = paste(\"Distribution of \", variable),\n        subtitle = sprintf(\"Categories: %d | Entropy: %.2f | Norm. Entropy: %.2f\", \n                           nrow(freq_df), entropy_value, norm_entropy),\n        x = \"\", y = \"Count\"\n      ) +\n      theme_minimal() +\n      theme(axis.text.x = element_text(angle = 45, hjust = 1))\n  }\n  \n  # Auto-adjust grid layout\n  num_plots <- min(9, length(categorical_cols))  # Max 9 plots\n  num_cols <- ceiling(sqrt(num_plots))  # Dynamic columns\n  num_rows <- ceiling(num_plots / num_cols)  # Dynamic rows\n  \n  # Generate plots\n  plot_list <- lapply(head(categorical_cols, num_plots), function(col) plot_bar(data, col))\n  grid::grid.newpage()\n  do.call(grid.arrange, c(plot_list, ncol = num_cols, nrow = num_rows))\n}\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Bivariate Analysis\n\n## 4.1 Relationship Between Target Variable and Numeric Predictors","metadata":{}},{"cell_type":"code","source":"target_var <- \"status\"\nviolin_plot_data <- data %>%\n    select(all_of(c(target_var, numeric_cols[1:min(6, length(numeric_cols))]))) %>%\n    pivot_longer(cols = -all_of(target_var), names_to = \"Variable\", values_to = \"Value\")\n\n  \nggplot(violin_plot_data, aes(x = .data[[target_var]], y = Value, fill = .data[[target_var]])) +\n  geom_violin(alpha = 0.6) +\n  geom_boxplot(width = 0.1, alpha = 0.8) +\n  scale_fill_viridis_d() +\n  facet_wrap(~ Variable, scales = \"free_y\", ncol = 3) +\n  labs(\n    title = \"Comparison of Numeric Variables by status Status\",\n    subtitle = \"Violin plots with boxplots inside\",\n    x = target_var,\n    y = \"Value\"\n  ) +\n  theme_custom()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"options(repr.plot.height = 14, repr.plot.width = 14)\ncor_matrix <- cor(data[, numeric_cols], use = \"pairwise.complete.obs\")\ncol <- colorRampPalette(c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\"))\ncorrplot(cor_matrix, method=\"color\", col=col(200),  \n         type=\"upper\", order=\"hclust\", \n         addCoef.col = \"black\", # Add coefficient of correlation\n         tl.col=\"black\", tl.srt=45, #Text label color and rotation\n         # Combine with significance\n        sig.level = 0.01, insig = \"blank\", \n         # hide correlation coefficient on the principal diagonal\n         diag=FALSE \n         )","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Network plot of correlations","metadata":{}},{"cell_type":"code","source":"\n# Set threshold for \"high correlation\"\nthreshold <- 0.3\n# Define correlation strength labels and corresponding colors\nlegend_labels <- c(\"Weak (< 0.3)\", \"Moderate (0.3 - 0.6)\", \"Strong (> 0.6)\")\ncorrelation_colors <- c(\"#CCCCCC\", \"#FFA500\", \"#FF0000\")  \n \n\n\n# Apply threshold to correlation matrix\ncor_filtered <- cor_matrix\ncor_filtered[abs(cor_filtered) < threshold] <- 0  # Filter weak correlations\ndiag(cor_filtered) <- 0  # Remove self-correlations\n\n# Ensure no missing values\ncor_filtered[is.na(cor_filtered)] <- 0\n\n# Create network graph from adjacency matrix\nnet <- graph_from_adjacency_matrix(\n  abs(cor_filtered),\n  mode = \"undirected\",\n  weighted = TRUE,\n  diag = FALSE\n)\n\n# Calculate node metrics\nbtw <- betweenness(net, normalized = TRUE)\nstrength <- strength(net)\n\n# Set vertex attributes\nV(net)$size <- 10 + 30 * rescale(strength)  # Normalize sizes\nV(net)$color <- colorRampPalette(brewer.pal(9, \"Blues\"))(100)[cut(rescale(btw), breaks = 100, labels = FALSE)]\n\n# Set edge attributes\nE(net)$width <- 1 + 5 * rescale(E(net)$weight)\nE(net)$color <- colorRampPalette(c(\"#CCCCCC\", \"#FFA500\", \"#FF0000\"))(100)[cut(rescale(E(net)$weight), breaks = 100, labels = FALSE)]\n\n# Create layout\nset.seed(42)\ngraph_layout <- layout_with_fr(net)\n\n# Plot network\nplot(net,\n     layout = graph_layout,\n     main = \"Feature Correlation Network\",\n     sub = paste(\"Threshold:\", threshold, \"| Node size = feature importance | Node color = centrality\"),\n     vertex.label.color = \"black\",\n     vertex.label.cex = 0.8,\n     edge.curved = 0.2,\n     edge.arrow.size = 0,\n     margin = c(0.15, 0.15, 0.15, 0.15)\n)\n\n# Move the correlation strength legend slightly left\nlegend(\"bottomleft\",\n       legend = legend_labels,\n       col = correlation_colors,\n       lwd = 4,\n       bty = \"n\",\n       cex = 0.8,\n       inset = c(-0.1, 0) # Move it slightly outside the plot\n)\n\n\n# Move the node properties legend slightly outside the plot\nlegend(\"topright\",\n       legend = c(\"Node size = Sum of correlations\", \n                  \"Node color = Betweenness centrality\"),\n       bty = \"n\",\n       cex = 0.8,\n       inset = c(-0.2, 0), # Move it slightly outside\n       xpd = TRUE \n)\n\n\n# Add top correlations\nif (ecount(net) > 0) {\n  top_edges <- head(E(net)[order(E(net)$weight, decreasing = TRUE)], 5)\n  if (length(top_edges) > 0) {\n    mtext(\"Strongest Correlations:\", side = 1, line = 3, adj = 0, cex = 0.9)\n    for (i in 1:length(top_edges)) {\n      edge <- top_edges[i]\n      edge_ends <- ends(net, edge)\n      v1 <- V(net)[edge_ends[1]]$name\n      v2 <- V(net)[edge_ends[2]]$name\n      weight <- round(E(net)[edge]$weight, 2)\n      mtext(paste0(v1, \" - \", v2, \": \", weight), side = 1, line = 3 + i, adj = 0, cex = 0.8)\n    }\n  }\n}\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Detect communities in the network\ncomm <- cluster_louvain(net)\n\nplot(comm, net, \n     layout = layout_with_fr(net),\n     main = \"Correlated Feature Communities\")\n\ncat(\"Community membership:\\n\")\nfor (i in 1:max(membership(comm))) {\n  cat(\"Community\", i, \":\", names(membership(comm))[membership(comm) == i], \"\\n\")\n}","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# 5. Multivariate Analysis\n\n## 5.1 Advanced Scatter Plot Matrix\n\n# Select a subset of the most interesting numeric variables","metadata":{}},{"cell_type":"code","source":"# Select a few key variables for bivariate analysis\nkey_vars <- c(\"loan_amount\", \"rate_of_interest\", \"income\",\"interest_rate_spread\", \"upfront_charges\", \"status\")\n\ndata %>%\n  select(all_of(key_vars)) %>%\n  ggpairs(aes(color = status, alpha = 0.5),\n          upper = list(continuous = \"cor\", combo = \"box_no_facet\"),\n          lower = list(continuous = \"points\", combo = \"dot_no_facet\"),\n          diag = list(continuous = \"densityDiag\"),\n          progress = FALSE) +\n  scale_color_viridis_d(option = \"D\", begin = 0.3, end = 0.7) +\n  scale_fill_viridis_d(option = \"D\", begin = 0.3, end = 0.7) +\n  labs(title = \"Bivariate Relationships with Status\") +\n  theme(axis.text = element_text(size = 8),\n        strip.text = element_text(size = 9))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.2 Dimensionality Reduction and Visualization\n### Sparse PCA\n\nSparse PCA aims to find principal components that explain the maximum variance while having as few non-zero loadings as possible. This helps identify the most important features (genes, clinical markers, etc.) that characterize different cancer subtypes.","metadata":{}},{"cell_type":"code","source":"num_data <- data %>% \n  select(any_of(numeric_cols))\n\n# Examine the dataset structure\ndim_desc <- paste(\"Dataset dimensions:\", paste(dim(num_data), collapse = \"x\"))\nfeature_desc <- paste(\"First few feature names:\", \n                      paste(colnames(num_data)[1:5], collapse=\", \"), \"...\")\ncat(dim_desc, \"\\n\", feature_desc)\n\n## Center and scale the data\n\nloan_scaled <- scale(num_data)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"library(dendextend)\n# Hierarchical clustering of features\nfeature_dist <- dist(t(loan_scaled))\nfeature_hclust <- hclust(feature_dist, method = \"ward.D2\")\nfeature_dend <- as.dendrogram(feature_hclust)\nfeature_dend <- color_branches(feature_dend, k = 5)\n\n# Create clustering visualization\nplot(feature_dend, main = \"Hierarchical Clustering of Numerical Features\",\n     xlab = \"\", sub = \"\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"library(elasticnet)\nlibrary(rospca)\nlibrary(PMA)\nloan_cov <- cov(loan_scaled)\nsparse_pca <- spca(loan_scaled,\n                  K = 5, # Number of components\n                  para = c(rep(0.4, 5)), # Sparsity parameters for each component\n                  type = \"predictor\",\n                  sparse = \"penalty\" # How do I induce sparsity?\n                )\n\nloadings_sparse <- sparse_pca$loadings\n# Prepare the data for visualization\nloadings_sparse_df <- as.data.frame(loadings_sparse)\ncolnames(loadings_sparse_df) <- paste0(\"SPC\", 1:ncol(loadings_sparse_df))\nloadings_sparse_df$Variable <- rownames(loadings_sparse_df)\nloadings_sparse_long <- pivot_longer(loadings_sparse_df,\n                                    cols = starts_with(\"SPC\"),\n                                    names_to = \"Component\",\n                                    values_to = \"Loading\")\n# Visualize the Sparse PCA Loadings\nggplot(loadings_sparse_long, aes(Variable, Loading, fill = abs(Loading))) +\n  geom_bar(stat = \"identity\", alpha = 0.8) +\n  facet_wrap(~ Component, ncol = 2) +\n  coord_flip() +\n  scale_fill_viridis(option = \"plasma\", direction = -1) +\n  labs(title = \"Sparse PCA Loadings\",\n  subtitle = \"First 5 Sparse Principal Components\",\n  x = NULL,\n  y = \"Loading Value\",\n  fill = \"Magnitude\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n   plot.subtitle = element_text(hjust = 0.5),\n   legend.position = \"bottom\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tuning the Sparsity Parameter\n\nThe sparsity parameter controls the trade-off between variance explained and interpretability. Let's examine how different lambda values affect sparsity:","metadata":{}},{"cell_type":"code","source":"# Try different sparsity parameters\nsparsity_levels <- seq(0.1, 0.9, 0.1)\nspca_results <- list()\n\nfor (i in seq_along(sparsity_levels)) {\n  spca_results[[i]] <- spca(loan_cov, K = 5, \n                           para = rep(sparsity_levels[i], 5),\n                           type = \"Gram\", sparse = \"penalty\")\n}\n\n# Select optimal sparsity based on variance explained vs sparsity tradeoff\nsparsity_metrics <- data.frame(\n  sparsity = sparsity_levels,\n  nonzero_loadings = sapply(spca_results, function(x) mean(colSums(x$loadings != 0))),\n  stringsAsFactors = FALSE\n)\n\n# Function to estimate variance explained for SPCA\ncalc_spca_var <- function(X, loadings) {\n  scores <- X %*% loadings\n  explained_var <- apply(scores, 2, var)\n  total_var <- sum(apply(X, 2, var))\n  return(explained_var / total_var * 100)\n}\n\n# Calculate variance explained for each sparsity level\nfor (i in seq_along(sparsity_levels)) {\n  sparsity_metrics$var_explained_pc1_5[i] <- \n    sum(calc_spca_var(loan_scaled, spca_results[[i]]$loadings)[1:5])\n}\n\n# Choose optimal sparsity level (example criterion)\nbest_idx <- which.max(sparsity_metrics$var_explained_pc1_5 / sparsity_metrics$nonzero_loadings)\noptimal_sparsity <- sparsity_levels[best_idx]\n\n# Display sparsity comparison\nknitr::kable(sparsity_metrics, digits = 2, \n             caption = paste(\"Sparsity-Variance Tradeoff (Optimal: \", optimal_sparsity, \")\"))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to calculate sparsity (% of zero loadings)\ncalculate_sparsity <- function(loadings_matrix) {\n  total_elements <- prod(dim(loadings_matrix))\n  zero_elements <- sum(loadings_matrix == 0)\n  return(zero_elements / total_elements * 100)\n}\n\n# Test different sparsity parameters\nlambda_values <- seq(0.1, 0.9, by = 0.1)\nsparsity_results <- data.frame(\n  lambda = lambda_values,\n  sparsity = numeric(length(lambda_values)),\n  variance_explained = numeric(length(lambda_values))\n)\n\nfor (i in seq_along(lambda_values)) {\n  lambda <- lambda_values[i]\n  \n  # Run sparse PCA \n  spca_result <- elasticnet::spca(loan_cov, \n                                 K = 4,\n                                 para = rep(lambda, 4),\n                                 type = \"Gram\",\n                                 sparse = \"penalty\")\n  \n  # Calculate sparsity\n  sparsity_results$sparsity[i] <- calculate_sparsity(spca_result$loadings)\n  \n  # Calculate variance explained \n  scores <- loan_cov %*% spca_result$loadings\n  var_explained <- sum(apply(scores, 2, var)) / sum(apply(loan_cov, 2, var)) * 100\n  sparsity_results$variance_explained[i] <- var_explained\n}\n\n\nsparsity_results_long <- pivot_longer(sparsity_results, \n                                     cols = c(\"sparsity\", \"variance_explained\"),\n                                     names_to = \"metric\",\n                                     values_to = \"value\")\n\nggplot(sparsity_results_long, aes(x = lambda, y = value, color = metric, group = metric)) +\n  geom_line(size = 1.2) +\n  geom_point(size = 3) +\n  labs(title = \"Sparsity-Variance Trade-off in Sparse PCA\",\n       x = \"Sparsity Parameter (λ)\",\n       y = \"Percentage\",\n       color = \"Metric\") +\n  scale_color_manual(values = c(\"#E69F00\", \"#56B4E9\"),\n                    labels = c(\"Sparsity (%)\", \"Variance Explained (%)\")) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        legend.position = \"bottom\",\n        legend.title = element_blank())","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Standard PCA","metadata":{}},{"cell_type":"code","source":"# Perform PCA\nset.seed(42)\nresults <- PCAtest(num_data,\n                  nperm = 1000,\n                  nboot = 1000,\n                  alpha = 0.05,\n                  #scale = FALSE,\n                  counter = FALSE,\n                  plot = TRUE\n                  )","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loan_pca <- prcomp(loan_scaled, scale = FALSE, center = TRUE)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"library(factoextra)\n# Kaiser Criterion\nget_eigenvalue(loan_pca)\n# We should pick five principal components, since the eigenvalues are over 1","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the PCA recipe\npca_prep <- recipe(status~., data =data) |> \n  step_normalize(all_numeric_predictors()) |> \n  step_pca(all_numeric_predictors(), num_comp = 5) |> \n  prep()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pca_prep","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize the contribution of variables to the components\n\ntidied_pca <- tidy(pca_prep, 2)\ntidied_pca |> \n  filter(component %in% paste0(\"PC\", 1:5)) |> \n  mutate(component = fct_inorder(component)) |> \n  ggplot(aes(value, terms, fill = terms)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~component, nrow = 1)+\n  labs(y = NULL)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"juice(pca_prep) %>%\n  ggplot(aes(PC1, PC2, label = status)) +\n  geom_point(aes(color = status), alpha = 0.7, size = 2) +\n  geom_text(check_overlap = TRUE, hjust = \"inward\", family = \"IBMPlexSans\") +\n  labs(color = NULL)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tidied_pca %>% \n  pivot_wider(names_from = component, values_from = value) %>% \n  select(-id) %>% \n  select(terms, PC1, PC2, PC3, PC4, PC5) -> standard_loadings\n\nstandard_loadings %>% \n  as.data.frame() -> standard_loadings\n\nrownames(standard_loadings) <- standard_loadings$terms\nstandard_loadings <- standard_loadings %>% \n  select(-terms) \n\nsparse_loading_subset <- loadings_sparse[, 1:5]\ncolnames(sparse_loading_subset) <- paste0(\"SPC\", 1:5)\n\n# Combine both loadings\nall_loadings <- cbind(standard_loadings, sparse_loading_subset)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Standard vs Sparse PCA Comparison","metadata":{}},{"cell_type":"code","source":"long_data <- all_loadings %>% \n  rownames_to_column(var = \"terms\") %>% \n  pivot_longer(cols = -terms, names_to = \"Feature\", values_to = \"Loading\")\n\nggplot(long_data, aes(Feature, terms, fill = Loading)) +\n  geom_tile() +\n  geom_text(aes(label = round(Loading, 2)), size = 3) +\n  scale_fill_gradient2(low = \"#fc8d62\", mid = \"white\", high = \"#66c2a5\", \n  midpoint = 0, limits = c(-1, 1)) +\n  labs(title = \"Sparse Vs. PCA Loadings\",\n  x = \"\", y = \"\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Interactive Biplots for Sparse PCA\nspca_scores <- loan_scaled %*% loadings_sparse[, 1:2]\nbiplot_data <- data.frame(\n  PC1 = spca_scores[, 1],\n  PC2 = spca_scores[, 2],\n  Default = as.factor(data$status)\n)\n\nggplot(biplot_data, aes(PC1, PC2, color = Default)) +\n  geom_point(size = 3, alpha = 0.7) +\n  geom_text(aes(label = Default), vjust = 1.5, size = 3) +\n  scale_color_manual(values = c(\"#E41A1C\", \"#377EB8\", \"#4DAF4A\")) +\n  labs(title = \"Sparse PCA Biplot\",\n       x = \"Sparse PC1\",\n       y = \"Sparse PC2\") +\n  theme_minimal()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate variable contributions (squared loadings)\ncontrib_df <- as.data.frame(loadings_sparse^2)\ncolnames(contrib_df) <- paste0(\"SPC\", 1:ncol(contrib_df))\ncontrib_df$Variable <- rownames(contrib_df)\n\ncontrib_long <- pivot_longer(contrib_df, \n                            cols = starts_with(\"SPC\"), \n                            names_to = \"Component\", \n                            values_to = \"Contribution\")\n\n# Sort by contribution within each component\ncontrib_long <- contrib_long %>%\n  group_by(Component) %>%\n  arrange(desc(Contribution)) %>%\n  ungroup()\n\n# Keep only non-zero contributions for clarity\ncontrib_long <- contrib_long %>% filter(Contribution > 0)\n\n# Create a bar chart of variable contributions\nggplot(contrib_long, aes(x = reorder(Variable, Contribution), y = Contribution, fill = Component)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  coord_flip() +\n  scale_fill_brewer(palette = \"Set1\") +\n  labs(title = \"Variable Contributions to Sparse Principal Components\",\n       x = NULL,\n       y = \"Squared Loading (Contribution)\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        legend.position = \"bottom\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Feature Importance and Selection","metadata":{}},{"cell_type":"markdown","source":"## Prep data","metadata":{}},{"cell_type":"code","source":"# Create initial train/test split (70/30)\nloan_split <- initial_split(data, prop = 0.7, strata = status)\nloan_train <- training(loan_split)\nloan_test <- testing(loan_split)\n\n# Create cross-validation folds for tuning\nloan_folds <- vfold_cv(loan_train, v = 5, strata = status)\n\n# Display split information\nsplit_info <- tribble(\n  ~Dataset, ~Rows, ~`status (Yes)`, ~`status (No)`, ~`status Rate (%)`,\n  \"Original\", nrow(data), \n  sum(data$status == \"Yes\"), \n  sum(data$status == \"No\"),\n  mean(data$status == \"Yes\") * 100,\n  \n  \"Training\", nrow(loan_train), \n  sum(loan_train$status == \"Yes\"), \n  sum(loan_train$status == \"No\"),\n  mean(loan_train$status == \"Yes\") * 100,\n  \n  \"Testing\", nrow(loan_test), \n  sum(loan_test$status == \"Yes\"), \n  sum(loan_test$status == \"No\"),\n  mean(loan_test$status == \"Yes\") * 100\n)\n\nkable(split_info, caption = \"Data Split Overview\") ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define preprocessing steps\nloan_recipe <- recipe(status ~ ., data = loan_train) %>%\n  \n  # Handle missing values\n  step_impute_knn(all_predictors(), neighbors = 5) %>%\n  # Group Rare categories into other category\n  step_other(all_nominal_predictors(), threshold = 0.2) %>% \n  # Treat new categories as new \n  step_novel(all_nominal_predictors()) %>% \n  \n  # Create dummy variables for categorical predictors\n  step_dummy(all_nominal_predictors()) %>%\n  \n  # Remove zero variance predictors\n  step_nzv(all_predictors()) %>%\n  \n  # Remove highly correlated predictors\n  step_corr(all_numeric_predictors(), threshold = 0.7) %>%\n  \n  # Normalize numeric predictors\n  step_normalize(all_numeric_predictors()) %>%\n  \n  # Handle class imbalance using SMOTE\n  themis::step_smote(status, over_ratio = 0.8)\n\n# Print the recipe\nloan_recipe","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare the recipe\nloan_prep <- prep(loan_recipe)\n\n# View the processed training data\nloan_train_processed <- juice(loan_prep)\n\n# Summarize the processed data\nloan_train_processed %>%\n  glimpse()\n\n# Count the number of predictors after preprocessing\nnum_predictors <- ncol(loan_train_processed) - 1\ncat(\"Number of predictors after preprocessing:\", num_predictors)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Machine Learning-Based Feature Importance","metadata":{}},{"cell_type":"markdown","source":"### Random Forest","metadata":{}},{"cell_type":"code","source":"library(vip)\nset.seed(42)\n\n# Set up a random forest model\nrf_model <- rand_forest() %>%\n  set_engine(\"randomForest\") %>%\n  set_mode(\"classification\") \n\nrf_wflow <- workflow() %>% \n  add_recipe(loan_recipe) %>% \n  add_model(rf_model)\n\nrf_wflow %>% \n  fit(data = loan_train) -> rf_fit\n\nfitted_rf <- extract_fit_parsnip(rf_fit)\nvip(fitted_rf, num_features = 15, geom = \"col\", aesthetics = list(fill = \"steelblue\")) +\n  labs(title = \"Random Forest Variable Importance\")","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5.2 XGBoost Feature Importance","metadata":{}},{"cell_type":"code","source":"library(xgboost)\n\nset.seed(42)\nxgb_model <- boost_tree() %>%\n  set_engine(\"xgboost\") %>%\n  set_mode(\"classification\")\n\nxgb_wflow <- workflow() %>%\n  add_recipe(loan_recipe) %>%\n  add_model(xgb_model)\n\nxgb_fit <- xgb_wflow %>% \n  fit(data = loan_train)\n\nfitted_xgb <- extract_fit_parsnip(xgb_fit)\n\nfeature_names <- fitted_xgb$fit$feature_names\n\nxgb_importance <- xgb.importance(\n  model = fitted_xgb$fit,\n  feature_names = feature_names  \n)\n\n\nxgb_importance_df <- xgb_importance %>%\n  slice_max(order_by = Gain, n = 15) %>% \n  mutate(Feature = factor(Feature, levels = rev(Feature))) \n\n\nggplot(xgb_importance_df, aes(x = Feature, y = Gain, fill = Gain)) +\n  geom_col(show.legend = FALSE) +\n  scale_fill_gradient(low = \"blue\", high = \"red\") +\n  coord_flip() +  \n  labs(title = \"XGBoost Feature Importance\", x = \"Features\", y = \"Importance\") +\n  theme_minimal()\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Recursive Feature Elimination\nRFE is a feature selection method that recursively removes the weakest feature(s) until the specified number of features is reached.","metadata":{}},{"cell_type":"code","source":"library(caret)\nlibrary(doParallel)\n# Set up parallel processing for faster computation\nregisterDoParallel(cores = 3)\n\n# Define control parameters for RFE\nrfe_control <- rfeControl(\n  functions = nbFuncs,  #Use Naiverace\n  method = \"cv\",        # Cross-validation\n  number = 5,           # 5-fold CV\n  verbose = FALSE,\n  allowParallel = TRUE\n)\n\n# Run RFE\nset.seed(123)\nrfe_result <- rfe(\n  x = loan_train_processed %>% select(-status),\n  y = loan_train_processed$status,\n  sizes = c(1:10, 15, 20),  \n  rfeControl = rfe_control\n)\n\nstopImplicitCluster()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print RFE results\nprint(rfe_result)\n\n# Plot the results\nplot(rfe_result, type = c(\"g\", \"o\"))\n\n# Get the optimal features\noptimal_vars <- predictors(rfe_result)\ncat(\"Optimal features selected by RFE:\", paste(optimal_vars, collapse = \", \"))\n\n# Plot the selected feature set performance\nggplot(data = data.frame(\n  Variables = rfe_result$results$Variables,\n  Accuracy = rfe_result$results$Accuracy\n)) +\n  geom_line(aes(x = Variables, y = Accuracy), color = \"blue\") +\n  geom_point(aes(x = Variables, y = Accuracy), color = \"red\", size = 3) +\n  geom_vline(xintercept = rfe_result$optsize, linetype = \"dashed\", color = \"darkred\") +\n  annotate(\"text\", x = rfe_result$optsize + 2, y = min(rfe_result$results$Accuracy), \n           label = paste(\"Optimal size:\", rfe_result$optsize), hjust = 0) +\n  labs(title = \"RFE Feature Selection Results\",\n       x = \"Number of Features\",\n       y = \"Accuracy\") +\n  theme_minimal()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Lasso Regression","metadata":{}},{"cell_type":"code","source":"doParallel::stopImplicitCluster()\n\nset.seed(123)\nlasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%\n  set_engine(\"glmnet\")\n\n# Set up the workflow\nlasso_wf <- workflow() %>%\n  add_recipe(loan_recipe) %>% \n  add_model(lasso_spec)\n\n# Set up grid of lambda values\nlambda_grid <- grid_regular(penalty(), levels = 50)\n\n# Set up resampling\nfolds <- vfold_cv(loan_train, v = 5, strata = status)\n\n# Tune LASSO model\nlasso_tune <- tune_grid(\n  lasso_wf,\n  resamples = folds,\n  grid = lambda_grid,\n  metrics = metric_set(roc_auc),\n  control = control_grid(allow_par = FALSE)\n)\n\n\n# Get best lambda\nbest_lambda <- lasso_tune %>%\n  select_best()\n\n# Finalize workflow and fit model\nlasso_final <- lasso_wf %>%\n  finalize_workflow(best_lambda) %>%\n  fit(data = loan_train)\n\n# Extract lasso coefficients\nlasso_coefs <- lasso_final %>%\n  extract_fit_parsnip() %>%\n  tidy() %>%\n  filter(estimate != 0, term != \"(Intercept)\") %>%\n  arrange(desc(abs(estimate)))\n\n# Visualize LASSO coefficients\nlasso_coefs %>%\n  mutate(term = str_replace_all(term, \"loan_purpose_\", \"Purpose: \")) %>%\n  slice_head(n = 20) %>%\n  ggplot(aes(x = reorder(term, abs(estimate)), y = estimate, fill = estimate > 0)) +\n  geom_col() +\n  scale_fill_manual(values = c(\"red\", \"blue\"), labels = c(\"Negative\", \"Positive\")) +\n  coord_flip() +\n  labs(title = \"Top 20 LASSO Coefficients\",\n       x = \"Features\",\n       y = \"Coefficient Estimate\",\n       fill = \"Direction\") +\n  theme_minimal()\n\n# Plot the tuning results\nautoplot(lasso_tune) +\n  labs(title = \"LASSO Tuning Results\")\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get non-zero coefficients across different lambda values\nlasso_model <- extract_fit_parsnip(lasso_final)$fit\nlasso_cv <- cv.glmnet(x = as.matrix(loan_train_processed %>% select(-status)),\n                      y = loan_train_processed$status,\n                      alpha = 1,\n                      family = \"binomial\")\n\n# Plot the coefficient path\nprint(plot(lasso_model, \"lambda\", label = TRUE))","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Elastic Net","metadata":{}},{"cell_type":"code","source":"library(doParallel)\ncl <- makeCluster(parallel::detectCores() - 1)\nregisterDoParallel(cl)\n\nset.seed(42)\nenet_spec <- logistic_reg(penalty = tune(), mixture = tune()) %>%\n  set_engine(\"glmnet\")\n\nenet_wf <- workflow() %>%\n  add_model(enet_spec) %>%\n  add_recipe(loan_recipe)\n\nenet_tune <- enet_wf %>%\n  tune_bayes(\n    resamples = folds,\n    param_info = parameters(penalty(range = c(1e-4, 1)), mixture(range = c(0, 1))),  \n    metrics = metric_set(roc_auc),\n    iter = 20,  \n    initial = 5,  \n    control = control_bayes(no_improve = 5, verbose = TRUE)  \n  )\n\nautoplot(enet_tune) +\n  labs(title = \"Elastic Net Tuning Results\")\n\nbest_enet <- enet_tune %>%\n  select_best()\n\n# Finalize workflow and fit model\nenet_final <- enet_wf %>%\n  finalize_workflow(best_enet) %>%\n  fit(data = loan_train)\n\n# Extract Elastic Net coefficients using direct access to model object\nmodel_fit <- extract_fit_parsnip(enet_final)\nglmnet_model <- model_fit$fit\n\n# Get coefficients for the specific lambda value\ncoef_matrix <- coef(glmnet_model, s = best_enet$penalty)\n# Convert sparse matrix to data frame\ncoef_df <- data.frame(\n  term = rownames(coef_matrix),\n  estimate = as.numeric(coef_matrix)\n) %>%\n  filter(estimate != 0, term != \"(Intercept)\") %>%\n  arrange(desc(abs(estimate)))\n\n# Display the top coefficients\nprint(coef_df)\n\nstopCluster(cl)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"coef_df %>%\n  slice_head(n = 20) %>%\n  ggplot(aes(x = reorder(term, abs(estimate)), y = estimate, fill = estimate > 0)) +\n  geom_col() +\n  scale_fill_manual(values = c(\"red\", \"blue\"), labels = c(\"Negative\", \"Positive\")) +\n  coord_flip() +\n  labs(title = \"Top 20 Elastic Net Coefficients\",\n       x = \"Features\",\n       y = \"Coefficient Estimate\",\n       fill = \"Direction\") +\n  theme_minimal()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Compare the different feature selection techniques","metadata":{}},{"cell_type":"code","source":"top_xgb <- xgb_importance %>% \n  slice_head(n = 10) %>% \n  pull(Feature)\n\ntop_rfe <- optimal_vars[1:min(10, length(optimal_vars))]\ntop_lasso <- lasso_coefs %>%\n  slice_head(n = 10) %>%\n  pull(term)\n\ntop_enet <- coef_df %>%\n  slice_head(n = 10) %>%\n  pull(term)\n\ntop_rf <- vip::vi(fitted_rf) %>% \n  arrange(desc(Importance)) %>%\n  slice_head(n = 10) %>% \n  pull(Variable)\n\ncomparison_df <- data.frame(\n  RandomForest = c(top_rf, rep(NA, 10 - length(top_rf))),\n  XGBoost = c(top_xgb, rep(NA, 10 - length(top_xgb))),\n  RFE = c(top_rfe, rep(NA, 10 - length(top_rfe))),\n  LASSO = c(top_lasso, rep(NA, 10 - length(top_lasso))),\n  ElasticNet = c(top_enet, rep(NA, 10 - length(top_enet)))\n)\nkable(comparison_df, caption = \"Top 10 Features from Each Method\") %>% \n  print()\n\n\ncount_feature_importance <- function(feature, methods_list) {\n  sum(sapply(methods_list, function(method) feature %in% method))\n}\n\nall_features <- unique(c(top_rf, top_xgb, \n  top_rfe, top_lasso, top_enet))\nall_features <- all_features[!is.na(all_features)]\n\n\nfeature_counts <- sapply(all_features, function(feat) {\ncount_feature_importance(feat, list(top_rf, top_xgb, \n              top_rfe, top_lasso, top_enet))\n})\n\n\nfeature_counts_df <- data.frame(\nFeature = names(feature_counts),\nCount = as.numeric(feature_counts)\n)\n\nfeature_counts_df %>%\narrange(desc(Count)) %>%\nslice_head(n = 20) %>%\nggplot(aes(x = reorder(Feature, Count), y = Count, fill = Count)) +\ngeom_bar(stat = \"identity\") +\nscale_fill_gradient(low = \"lightblue\", high = \"darkblue\") +\ncoord_flip() +\nlabs(title = \"Feature Importance Consensus\",\nsubtitle = \"Number of methods that selected the feature in their top 10\",\nx = \"Feature\",\ny = \"Count of Methods\") +\ntheme_minimal() +\ntheme(plot.title = element_text(face =\"bold\"))\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bre","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# How do these models perform based on the  selected features?\n# Define a function to train and evaluate a model\nevaluate_feature_set <- function(features, name) {\n  \n  # Prep the recipe\n  feature_prep <- prep(loan_recipe)\n  train_processed <- bake(feature_prep, new_data = loan_train)\n  test_processed <- bake(feature_prep, new_data = loan_test)\n  \n  # Train a random forest model\n  rf_model <- rand_forest() %>%\n    set_engine(\"randomForest\") %>%\n    set_mode(\"classification\") %>%\n    fit(status ~ ., data = train_processed)\n  \n  # Make predictions\n  preds <- predict(rf_model, test_processed, type = \"prob\") %>%\n    bind_cols(test_processed) %>%\n    select(status, .pred_Yes)\n  \n  # Calculate performance metrics\n  roc_obj <- roc(preds$status, preds$.pred_Yes)\n  auc_value <- auc(roc_obj)\n  \n  # Return results\n  return(list(\n    name = name,\n    auc = auc_value,\n    roc = roc_obj,\n    features = features\n  ))\n}\n\nget_base_features <- function(terms) {\n  base_features <- unique(sapply(terms, function(term) {\n    \n    # Special case handling\n    term <- gsub(\"submission_of_application_to_inst\", \"submission_of_application\", term)\n    \n    # Remove common suffixes\n    term <- gsub(\"_(other|EXP|CRIF|to_inst|to)$\", \"\", term)\n    \n    # Remove trailing underscores with categories (like loan_purpose_auto -> loan_purpose)\n    term <- gsub(\"_(auto|p4|mortgage|south|Male|X[0-9.]+)$\", \"\", term)\n    \n    return(term)\n  }))\n  \n  return(base_features)\n}\n\n\nfeatures <- c(\"credit_type_other\", \"rate_of_interest\", \"upfront_charges\", \"interest_rate_spread\",\n              \"dtir1\", \"ltv\", \"income\", \"property_value\", \"credit_score\", \n              \"co_applicant_credit_type_EXP\", \"neg_ammortization_other\", \n              \"submission_of_application_to_inst\", \"business_or_commercial_other\", \n              \"approv_in_adv_other\", \"credit_type_CRIF\", \"credit_type_EXP\", \n              \"occupancy_type_other\", \"loan_limit_other\", \"loan_purpose_auto\",\n              \"loan_purpose_p4\", \"region_south\", \n              \"gender_Male\", \"age_X55.64\")\n\n# Get the base features for the top models\n\nrf_features <- get_base_features(top_rf)\nxgb_features <- get_base_features(top_xgb)\nrfe_features <- get_base_features(top_rfe)\nlasso_features <- get_base_features(top_lasso)\nenet_features <- get_base_features(top_enet)\n\n# Get consensus features (features that appear in multiple methods)\nall_base_features <- unique(c(rf_features, xgb_features, rfe_features, \n  get_base_features(top_lasso), get_base_features(top_enet)))\nall_base_features <- all_base_features[!is.na(all_base_features)]\n\n\nfeature_counts <- sapply(all_base_features, function(feat) {\n  sum(\n  feat %in% rf_features,\n  feat %in% xgb_features,\n  feat %in% rfe_features,\n  feat %in% get_base_features(top_lasso),\n  feat %in% get_base_features(top_enet))\n  })\n  \nconsensus_features <- names(feature_counts[feature_counts >= 3])\n\n# Evaluate each feature set\nset.seed(42)\nresults_list <- list(\nevaluate_feature_set(rf_features, \"Random Forest\"),\nevaluate_feature_set(xgb_features, \"XGBoost\"),\nevaluate_feature_set(rfe_features, \"RFE\"),\nevaluate_feature_set(get_base_features(top_lasso), \"LASSO\"),\nevaluate_feature_set(get_base_features(top_enet), \"Elastic Net\"),\nevaluate_feature_set(consensus_features, \"Consensus (3+ methods)\")\n)\n\n# Plot ROC curves\ncolors <- c(\"blue\", \"green\", \"purple\", \"orange\", \"brown\", \"black\")\nplot(results_list[[1]]$roc, col = colors[1], main = \"ROC Curves for Different Feature Sets\")\nfor(i in 2:length(results_list)) {\nlines(results_list[[i]]$roc, col = colors[i])\n}\nlegend(\"bottomright\", \nlegend = sapply(results_list, function(r) paste0(r$name, \" (AUC = \", round(r$auc, 3), \")\")),\ncol = colors,\nlwd = 2)\n  \n# Compare AUC values\nauc_df <- data.frame(\n  Method = sapply(results_list, function(r) r$name),\n  AUC = sapply(results_list, function(r) r$auc),\n  Features = sapply(results_list, function(r) length(r$features))\n)\n\n# Plot AUC comparison\nauc_df %>%\n  ggplot(aes(x = reorder(Method, AUC), y = AUC, fill = Features)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_gradient(low = \"lightblue\", high = \"darkblue\") +\n  coord_flip() +\n  labs(title = \"Model Performance with Different Feature Sets\",\n       x = \"Feature Selection Method\",\n       y = \"AUC Score\",\n       fill = \"Number of Features\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Final Feature Selection","metadata":{}},{"cell_type":"code","source":"# Get the best performing feature set\nbest_method <- auc_df %>%\n  arrange(desc(AUC)) %>%\n  slice_head(n = 1)\n\nbest_method_name <- best_method$Method\nbest_method_idx <- which(sapply(results_list, function(r) r$name) == best_method_name)\nbest_features <- results_list[[best_method_idx]]$features\n\n# Print the recommendation\ncat(\"## Feature Selection Recommendation\\n\\n\")\ncat(\"Based on our analysis, the *\", best_method_name, \"* approach provides the best performance with an AUC of \", \n    round(best_method$AUC, 3), \" using \", best_method$Features, \" features.\\n\\n\", sep = \"\")\ncat(\"The recommended features for the loan default prediction model are:\\n\\n\")\ncat(paste(\"- \", best_features, collapse = \"\\n\"))\n\nfinal_recipe <- recipe(status ~ ., data = loan_train %>% \n  select(status, all_of(best_features))) %>% # Just join the previous recipe from here\n  \n  # Handle missing values\n  step_impute_knn(all_predictors(), neighbors = 5) %>%\n  # Group Rare categories into other category\n  step_other(all_nominal_predictors(), threshold = 0.2) %>% \n  # Treat new categories as new \n  step_novel(all_nominal_predictors()) %>% \n  \n  # Create dummy variables for categorical predictors\n  step_dummy(all_nominal_predictors()) %>%\n  \n  # Remove zero variance predictors\n  step_nzv(all_predictors()) %>%\n  \n  # Remove highly correlated predictors\n  step_corr(all_numeric_predictors(), threshold = 0.7) %>%\n  \n  # Normalize numeric predictors\n  step_normalize(all_numeric_predictors()) %>%\n  \n  # Handle class imbalance using SMOTE\n  themis::step_smote(status, over_ratio = 0.8)\n\nloan_pca_recipe <- recipe(status ~ ., data = loan_train %>% \n    select(status, all_of(best_features))) %>% \n    step_impute_knn(all_predictors(), neighbors = 5) %>%\n    step_other(all_nominal_predictors(), threshold = 0.2) %>% \n    step_novel(all_nominal_predictors()) %>% \n    step_dummy(all_nominal_predictors()) %>%\n    step_nzv(all_predictors()) %>%\n    step_corr(all_numeric_predictors(), threshold = 0.7) %>%\n    step_normalize(all_numeric_predictors()) %>%\n    step_pca(all_numeric_predictors(), num_comp = 5) %>% \n    themis::step_smote(status, over_ratio = 0.8)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_recipe","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the models \nrf_spec <- rand_forest(\n  mtry = tune(),\n  trees = 500,\n  min_n = tune()\n) %>%\n  set_engine(\"ranger\", importance = \"impurity\") %>%\n  set_mode(\"classification\")\n\n\nxgb_spec <- boost_tree(\n  trees = 500,\n  tree_depth = tune(),\n  min_n = tune(),\n  loss_reduction = tune(),\n  sample_size = tune(),\n  mtry = tune(),\n  learn_rate = tune()\n) %>%\n  set_engine(\"xgboost\") %>%\n  set_mode(\"classification\")\n\nlog_reg_spec <- logistic_reg(\n  penalty = tune(),\n  mixture = tune()\n) %>%\n  set_engine(\"glmnet\") %>%\n  set_mode(\"classification\")\n\nnnet_spec <-\n  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>%\n  set_engine('nnet') %>%\n  set_mode('classification')\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Hyperparameter Tuning\n### Tune Race Anova","metadata":{}},{"cell_type":"code","source":"# Perform Hyperparameter tuning(Tune Race Anova) and fit the models\nlibrary(finetune)\ncl <- makePSOCKcluster(detectCores() - 1)\nregisterDoParallel(cl)\nloan_workflow <- workflow_set(\n  preproc = list(loan_recipe, loan_pca_recipe),\n  models = list(\n    randomforest = rf_spec,\n    xgboost = xgb_spec,\n    logistic_regression = log_reg_spec,\n    nnet = nnet_spec\n  )\n)\n\nmetrics <- metric_set(yardstick::accuracy, roc_auc, yardstick::sensitivity, yardstick::specificity, brier_class, yardstick::f_meas)\nrace_ctrl <- control_race(\n  save_pred = TRUE,\n  parallel_over = \"everything\",\n  save_workflow = TRUE\n)\n\nrace_results <- loan_workflow %>%\n  workflow_map(\n    seed = 42,\n    fn = \"tune_race_anova\",\n    resamples = loan_folds,\n    grid = 10,\n    metrics = metrics,\n    control = race_ctrl\n  )\nstopCluster(cl)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"race_results <- race_results %>% \n  mutate(wflow_id = gsub(\"recipe_1\", \"normal\", wflow_id),\n         wflow_id = gsub(\"recipe_2\", \"pca\", wflow_id))\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"race_results","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Rank the results based on the F1-score\nrace_results %>% \n  rank_results() %>% \n  filter(.metric == \"f_meas\") %>% \n  select(model, .config, f1_score = mean, rank)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"autoplot(race_results,\n  rank_metric = \"f_meas\",\n  metric = \"f_meas\",\n  select_best = TRUE) +\n  geom_text(aes(y = mean - 0.05, label = wflow_id), angle = 90, hjust = 1) +\n  coord_cartesian(clip = \"off\") +\n  theme(plot.margin = margin(b = 120)) ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract all metrics and predictions\nall_metrics <- collect_metrics(race_results)\nall_predictions <- collect_predictions(race_results)\n# 1. Overall Performance Comparison\noverall_comparison <- race_results %>%\n  collect_metrics() %>%\n  group_by(wflow_id, .metric) %>%\n  summarise(\n    mean_perf = mean(mean),\n    sd_perf = sd(mean),\n    .groups = \"drop\"\n  ) %>%\n  arrange(wflow_id, mean_perf)\n\noverall_comparison","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. ROC Curves Comparison\nroc_curves <- all_predictions %>%\n  group_by(wflow_id) %>%\n  roc_curve(truth = status, .pred_Yes) %>%\n  autoplot() +\n  theme_custom() +\n  labs(\n      title = \"Roc-Auc Curves Comparison\",\n      color = \"Model\"\n    )\n\nroc_curves","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Precision-Recall Curves\npr_curves <- all_predictions %>%\n  group_by(wflow_id) %>%\n  pr_curve(truth = status, .pred_Yes) %>%\n  autoplot() +\n  theme_minimal() +\n  labs(\n    title = \"Precision-Recall Curves Comparison\",\n    color = \"Model\"\n  )\npr_curves","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Performance Distribution Boxplots\nmetric_distributions <- all_metrics %>%\n  ggplot(aes(x = wflow_id, y = mean, fill = wflow_id)) +\n  geom_boxplot() +\n  facet_wrap(~.metric, scales = \"free_y\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(\n    title = \"Performance Distribution Across Models\",\n    x = \"Model\",\n    y = \"Metric Value\"\n  )\n\nmetric_distributions","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Model Calibration\ncalibration_plots <- all_predictions %>%\n  group_by(wflow_id) %>%\n  mutate(pred_bin = cut(.pred_Yes, breaks = seq(0, 1, by = 0.1))) %>%\n  group_by(wflow_id, pred_bin) %>%\n  summarise(\n    observed_prob = mean(status == \"Yes\"),\n    predicted_prob = mean(.pred_Yes),\n    .groups = \"drop\"\n  ) %>%\n  ggplot(aes(x = predicted_prob, y = observed_prob, color = wflow_id)) +\n  geom_line() +\n  geom_point() +\n  geom_abline(linetype = \"dashed\") +  # Ideal calibration line\n  theme_minimal() +\n  labs(title = \"Model Calibration Plot\", x = \"Predicted Probability\", y = \"Observed Frequency\")\n\ncalibration_plots","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Model Rankings\nmodel_rankings <- all_metrics %>%\n  group_by(.metric, wflow_id) %>%\n  summarise(mean = mean(mean), .groups = \"drop\") %>%\n  mutate(rank = rank(-mean)) %>%\n  pivot_wider(names_from = .metric, values_from = c(mean, rank)) %>%\n  arrange(rank_roc_auc) %>%\n  kable(caption = \"Average model rankings based on selected metrics\")\n\nprint(model_rankings)\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure `wflow_id` is a factor (categorical variable)\nall_metrics <- all_metrics %>%\n  mutate(wflow_id = as.factor(wflow_id))\n\n# Ensure each fold is treated as a blocking factor\n# Create `id` to represent the blocking factor (folds)\nall_metrics <- all_metrics %>%\n  mutate(id = rep(1:floor(n()/length(unique(wflow_id))),\n                  each = length(unique(wflow_id)), length.out = n()))\n\n# Filter only rows where `.metric` is \"f1 score\"\nroc_metrics <- all_metrics %>%\n  filter(.metric == \"f_meas\")\n\n# Ensure `mean` (roc_auc values) is numeric\nroc_metrics <- roc_metrics %>%\n  mutate(mean = as.numeric(mean))\n\n# Check for missing values\nmissing_data <- roc_metrics %>%\n  group_by(id, wflow_id) %>%\n  summarise(n = n(), .groups = \"drop\") %>%\n  pivot_wider(names_from = wflow_id, values_from = n)\n\n\n# Create properly formatted data for Friedman test\nfriedman_data <- roc_metrics %>%\n  select(id, wflow_id, mean) %>%  \n  pivot_wider(\n    names_from = wflow_id,\n    values_from = mean\n  )\n\n\n# Perform Friedman test\nfriedman_result <- friedman.test(as.matrix(friedman_data[,-1]))\n\nprint(\"\\nFriedman test results:\")\nprint(friedman_result)\n\n# If Friedman test is significant, perform post-hoc analysis\nif(friedman_result$p.value < 0.05) {\n  # Perform pairwise Wilcoxon signed rank tests with p-value adjustment\n  posthoc <- all_metrics %>%\n    wilcox_test(\n      mean ~ wflow_id,\n      paired = TRUE,\n      p.adjust.method = \"bonferroni\"\n    )\n  \n  print(\"\\nPost-hoc analysis results:\")\n  print(posthoc)\n}\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stability Plot Analysis\nstability_plot <- all_metrics %>%\n  # Filter for relevant metrics\n  filter(.metric %in% c(\"accuracy\", \"roc_auc\", \"sensitivity\", \"specificity\")) %>%\n  # Calculate stability metrics\n  group_by(wflow_id, .metric) %>%\n  summarise(\n    mean_perf = mean(mean),\n    sd_perf = sd(mean),\n    cv = sd_perf / mean_perf * 100,\n    .groups = \"drop\"\n  ) %>%\n  # Create plot\n  ggplot(aes(x = reorder(wflow_id, cv), y = cv, fill = .metric)) +\n  geom_col(position = position_dodge(width = 0.8),\n           width = 0.7,\n           color = \"black\",\n           alpha = 0.8) +\n  # Custom color palette\n  scale_fill_brewer(palette = \"Set2\",\n                    labels = c(\"Accuracy\", \"ROC-AUC\", \"Sensitivity\", \"Specificity\")) +\n  # Formatting\n  scale_y_continuous(\n    #limits = c(0, max(cv) * 1.1),\n    labels = function(x) paste0(round(x, 1), \"%\"),\n    expand = expansion(mult = c(0, 0.05))\n  ) +\n  # Clean theme\n  theme_minimal(base_size = 12, base_family = \"Arial\") +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", margin = margin(b = 10)),\n    plot.subtitle = element_text(size = 12, color = \"grey40\", margin = margin(b = 20)),\n    plot.caption = element_text(size = 10, color = \"grey40\", margin = margin(t = 10)),\n    axis.title = element_text(size = 12, face = \"bold\"),\n    axis.text = element_text(size = 11),\n    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),\n    legend.position = \"top\",\n    legend.title = element_blank(),\n    legend.text = element_text(size = 11),\n    legend.margin = margin(b = 10),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.grid.major.y = element_line(color = \"grey90\"),\n    plot.margin = margin(20, 20, 20, 20)\n  ) +\n  # Labels\n  labs(\n    title = \"Model Performance Stability Analysis\",\n    subtitle = \"Lower Coefficient of Variation (CV%) indicates more consistent performance across folds\",\n    x = \"Model Workflow\",\n    y = \"Coefficient of Variation (%)\",\n    caption = \"Note: CV% calculated across all cross-validation folds\"\n  )\n\n# Display the plot\nstability_plot","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"performance_table <- overall_comparison %>%\n  arrange(desc(mean_perf)) %>% # Sort by performance\n  kable(format = \"html\", digits = 3, caption = \"Model Performance Summary\") %>%\n  kable_styling(full_width = FALSE, bootstrap_options = c(\"striped\", \"hover\", \"condensed\")) %>%\n  row_spec(0, bold = TRUE) %>%  # Make header bold\n  column_spec(2:3, width = \"15em\") %>% # Adjust column width\n  pack_rows(\"Top Performing Models\", 1, 3, label_row_css = \"font-weight: bold; background-color: #e6f3ff;\") # Highlight top 3\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"all_metrics %>%\n  group_by(.metric, wflow_id) %>%\n  summarise(mean = mean(mean), .groups = \"drop\") %>%\n  mutate(rank = rank(-mean)) %>%\n  pivot_wider(names_from = .metric, values_from = c(mean, rank)) %>%\n  arrange(rank_roc_auc) %>%\n  mutate(wflow_id = as.character(wflow_id))-> model_rankings\n\nmodel_rankings","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_wflow <- model_rankings %>%\n  slice(1) %>% \n  pull(wflow_id) \n\n\nbest_results <- race_results %>% \n  extract_workflow_set_result(best_wflow) %>% \n  select_best(metric = \"f_meas\")\n\nprint(best_results)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"race_results %>% \n  extract_workflow(best_wflow) %>% \n  finalize_workflow(best_results) %>% \n  last_fit(loan_split) -> final_fit","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"collect_metrics(final_fit)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_fit %>% \n  collect_predictions() %>% \n  conf_mat(truth = status, \n      estimate = .pred_class) -> conf_mat\n\nconfusion_matrix <- conf_mat %>%\n  autoplot(type = \"heatmap\") +\n  labs(title = \"Confusion Matrix on Test Data\") +\n  scale_fill_gradient(low = \"#f7fbff\", high = \"#08306b\") +\n  theme_minimal()\n\nfinal_metrics <- collect_metrics(final_fit)\nprint(list(final_metrics, confusion_matrix))\n\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vip(extract_fit_parsnip(final_fit), num_features = 10, geom = \"col\") +\n  theme_minimal() +\n  labs(title = \"XGBoost Feature Importance\",\n       subtitle = \"Top 10 most influential features\") +\n  theme(plot.title = element_text(face = \"bold\", size = 16),\n        plot.subtitle = element_text(face = \"italic\", size = 12),\n        axis.text.y = element_text(size = 10),\n        panel.grid.major.x = element_line(linetype = \"dashed\", color = \"gray80\"),\n        panel.grid.minor = element_blank(),\n        panel.grid.major.y = element_blank()) +\n  scale_fill_viridis_c()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"library(DALEX)       # For model explanations\nlibrary(DALEXtra)    # Extensions for DALEX\nlibrary(vip)         # Variable importance plots\nlibrary(lime) ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}